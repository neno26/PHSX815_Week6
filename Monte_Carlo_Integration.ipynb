{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical integration: Monte Carlo vs the Determinists\n",
    "\n",
    "- Implement a Monte Carlo integration to a function in one or more dimensions.\n",
    "\n",
    "- Quantify the accuracy of your MC integral as a function of the number of sample points and compare with the accuracy of your deterministic methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My function of choice: $ f(x) = xsin(x)$ \n",
    " - Derivative: $ f'(x) = sin(x) + xcos(x) $\n",
    " \n",
    " - Integral: $\\int \\mathrm{xsin(x)} \\mathrm{d}x$ = $ sin(x) - xcos(x) $\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Methods:\n",
    " \n",
    " - Midpoint rule\n",
    " - Gaussian Quadrature\n",
    " - Monte Carlo\n",
    " - Trapizoidal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.special import legendre\n",
    "from numpy.polynomial.legendre import legroots as leg\n",
    "from scipy.special import roots_legendre as rootleg\n",
    "import Random as Random\n",
    "\n",
    "# Our function to be integrated, takes a value\n",
    "def Function(value):\n",
    "    return(value*np.sin(value))\n",
    "\n",
    "\n",
    "# rule that numerically integrates according: takes a val, a lower bound and upper bound to be intgrated \n",
    "def Midpoint(step, low, high):\n",
    "    \n",
    "    value1 = []\n",
    "    value2 = 0\n",
    "    width  = (high-low)/step  \n",
    "     \n",
    "    for n in range (1,step+1):                      #to offset the initial value 0 which python counts from.\n",
    "        sub_int_mid = low + (n-1/2)*width           #Midpoint of each subinterval\n",
    "        value1.append(Function(sub_int_mid))\n",
    "    value2          = width*np.sum(value1)          #approximated area\n",
    "    return(value2)\n",
    "\n",
    "#Implementation of trapazoidal rule\n",
    "def Trap(step, low, high):\n",
    "    width = (high-low)/step\n",
    "    value = [Function(low)]\n",
    "    \n",
    "    for i in range(1,step):\n",
    "        value.append(2*Function(low + i*width))\n",
    "    value.append(Function(high))\n",
    "    return(0.5*width*np.sum(value))\n",
    "\n",
    "#Implementation of Gaussian quadrature on arbitrary intervals\n",
    "def Gauss(step, low, high):\n",
    "    width  = 0.5*(low + high)\n",
    "    roots  = rootleg(step)[0]\n",
    "    weights = rootleg(step)[1]\n",
    "    value  = []\n",
    "    \n",
    "    for i in range(len(roots)):\n",
    "        t = roots[i]\n",
    "        legen = 0.5*(high-low)*weights[i]*Function(0.5*(low + high) + 0.5*(high-low)*t)\n",
    "        value.append(legen)\n",
    "    return(np.sum(value)) \n",
    "\n",
    "#Calculates the relative error of the different rules (fun)\n",
    "def Relative_Error(fun, step, low, high):\n",
    "    integral_high   = np.sin(high)-high*np.cos(high)\n",
    "    integral_low    = np.sin(low)-low*np.cos(low)\n",
    "    integral        = integral_high - integral_low\n",
    "    return(abs(integral-fun(step,low,high))/integral)*100\n",
    "\n",
    "\n",
    "def Plot(f, step, low, high):\n",
    "    \n",
    "    X_Values  = []\n",
    "    Y_Values  = []\n",
    "    Rel_Error = []\n",
    "    \n",
    "    \n",
    "    for i in range(1,step+1):\n",
    "        a   = f(i,low,high)\n",
    "        err = Relative_Error(f, i, low, high)\n",
    "        X_Values.append(i)\n",
    "        Y_Values.append(a)\n",
    "        Rel_Error.append(err)\n",
    "    \n",
    "\n",
    "    fig   = plt.figure()\n",
    "    axes1 = fig.add_axes([0.1, 0.1, 0.8, 0.8]) # main axes\n",
    "    axes2 = fig.add_axes([0.50, 0.25, 0.40, 0.35],facecolor='y') # inset axes\n",
    "    axes1.plot(X_Values, Y_Values,'go--')\n",
    "    axes2.plot(X_Values, Rel_Error,'b')\n",
    "    axes1.set_title(\"Value Vs Steps\")\n",
    "    axes2.set_title(\"Error Vs Steps\")\n",
    "    axes1.set_xlabel('# Of Sub-Interval')\n",
    "    axes2.set_xlabel('# Of Sub-Interval')\n",
    "    axes1.set_ylabel('Value')\n",
    "    axes2.set_ylabel('Value')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Monte Carlo Implmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Monte_Carlo(sample,low,high):\n",
    "    value = []\n",
    "    \n",
    "    for _ in range(sample):\n",
    "        x = np.random.rand()\n",
    "        value.append(Function(x))\n",
    "    return(high-low)*sum(value)/sample\n",
    "\n",
    "def MC_variance(sample,high):\n",
    "    int_max = high # this is the max of our integration range\n",
    "    \n",
    "    # get the average of squares\n",
    "    running_total = 0\n",
    "    for i in range(sample):\n",
    "        x = np.random.rand()\n",
    "        running_total += Function(x)\n",
    "    sum_of_sqs = running_total*int_max/sample\n",
    "    \n",
    "    # get square of average\n",
    "    running_total = 0\n",
    "    for i in range(sample):\n",
    "        x = np.random.rand()\n",
    "        running_total += Function(x)\n",
    "    sq_ave = (int_max*running_total/sample)**2\n",
    "    \n",
    "    return sum_of_sqs - sq_ave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The monte carlo evaluation is:1.525916951586139\n",
      "The monte carlo variance is:-2.4249839002606577\n",
      "The value of of the integral using the trap method is: -6.357038455828771\n",
      "The relative error of the trap method is: -0.07673509820067714\n"
     ]
    }
   ],
   "source": [
    "print(\"The monte carlo evaluation is:\" + str(Monte_Carlo(5000,2,7)))\n",
    "print(\"The monte carlo variance is:\" + str(MC_variance(5000,7)))\n",
    "\n",
    "print(\"The value of of the integral using the trap method is: \" + str(Trap(50,2,7)))\n",
    "print(\"The relative error of the trap method is: \"+ str(Relative_Error(Trap,50,2,7))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion:\n",
    "\n",
    "Unless it's boostrapped, the monte carlo method is near useless for certain classes of function. \n",
    "The deterministic models win hands down. I've used different distributions -normal being the better of them - which sorta made it better, but the value still fluctuated greatly. Also, if one is stuck in a solution region, it doesn't matter the number of sample.  Moreover, for the more special of distributions - such as a normal - I needed ot know a prior where to set sigma and mu. Whereas the deterministic methods simply needs more steps. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
